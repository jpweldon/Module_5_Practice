{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decisive Probability Distributions\n",
    "\n",
    "In this activity, you’ll use the Alpaca API to gather pricing information for six stocks. Then, you’ll use this information to plot probability distributions for the daily returns of the stocks. Finally, you’ll determine the most and the least volatile stocks.\n",
    "Instructions:\n",
    "\n",
    "1. Create an environment file (`.env`) in the root of the `Unsolved` folder. This file will hold your Alpaca API and secret keys.\n",
    "\n",
    "2. Load the Alpaca API and secret keys into `decisive_probability_distributions.ipynb`, and set the values equal to variables of the same name.\n",
    "\n",
    "3. Create the Alpaca API `REST` object by calling the Alpaca `tradeapi.REST` function and setting `alpaca_api_key`, `alpaca_secret_key`, and `api_version`.\n",
    "\n",
    "4. Use the Alpaca SDK to make an API call that gets one year of daily stock information ( 2019-05-01 to 2020-05-01) for the following stock tickers:\n",
    "\n",
    "    - `SPY` (SPDR S&P 500 ETF Trust)\n",
    "\n",
    "    - `LUV` (Southwest Airlines)\n",
    "\n",
    "    - `DIS` (Disney) \n",
    "\n",
    "    - `AAPL` (Apple)\n",
    "\n",
    "    - `SBUX` (Starbucks)\n",
    "\n",
    "    - `ZM` (Zoom)\n",
    "\n",
    "> **Hint** Remember to set the tickers, time frame, start and end dates (‘2019-05-01’ and ‘2020-05-01’) and the number of rows returned. Then use the Alpaca `get_barset` function to make the API call. Be sure to set the `df` property at the end of the `get_barset` function so that the API response is returned as a DataFrame.\n",
    "\n",
    "5. Create a new DataFrame that holds the closing prices of each stock.\n",
    "\n",
    "6. Generate a daily returns DataFrame that’s based on the closing prices of each stock.\n",
    "\n",
    "7. Generate the summary statistics for the daily returns DataFrame. This provides your first review of the distribution information for your stocks.\n",
    "\n",
    "8. Visualize the distribution of the daily returns DataFrame by creating a histogram plot and a density plot.\n",
    "\n",
    "> **Hint** Generate only two plots. Both the histogram and the density plot will show the data for all six stocks.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[Alpaca API Docs](https://alpaca.markets/docs/api-documentation/)\n",
    "\n",
    "[Pandas Histogram plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html)\n",
    "\n",
    "[Pandas Density plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the required libraries and dependencies\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create your `.env` file at the root of your Unsolved folder. It should include your Alpaca API and secret keys. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Alpaca API and secret keys into `decisive_probability_distributions.ipynb`, and set the values equal to variables of the same name.\n",
    "\n",
    "* Load the environment variable by calling the `load_dotenv()` function.\n",
    "* Set the value of the variables `alpaca_api_key` and `alpaca_secret_key` equal to their respective environment variables. \n",
    "* Confirm the variables are available by checking the `type` of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables by calling the load_dotenv function\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set Alpaca API key and secret by calling the os.getenv function and referencing the environment variable names\n",
    "# Set each environment variable to a notebook variable of the same name\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Check the values were imported correctly by evaluating the type of each\n",
    "display(type(alpaca_api_key))\n",
    "display(type(alpaca_secret_key))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Alpaca API `REST` object by calling the Alpaca `tradeapi.REST` function and setting `alpaca_api_key`, `alpaca_secret_key`, and `api_version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your Alpaca API REST object by calling Alpaca's tradeapi.REST function\n",
    "# Set the parameters to your alpaca_api_key, alpaca_secret_key and api_version=\"v2\" \n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use the Alpaca SDK to make an API call that gets one year of daily stock information ( 2019-05-01 to 2020-05-01) for the following stock tickers: SPY, LUV, DIS, AAPL, SBUX, and ZM. \n",
    "\n",
    "* Create the list for the required `tickers`\n",
    "* Set the values for `start_date` and `end_date` using the `pd.Timestamp` function. The dates should be 2019-05-01 through 2020-05-01.\n",
    "* Set the `timeframe` value to 1 day.\n",
    "* Create the `portfolio_prices_df` DataFrame by setting it equal to the `alpaca.get_barset` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPY', 'LUV', 'DIS', 'AAPL', 'SBUX', 'ZM']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list for the required tickers\n",
    "tickers = [\"SPY\", \"LUV\", \"DIS\", \"AAPL\", \"SBUX\", \"ZM\"]\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for start_date and end_date using the pd.Timestamp function\n",
    "# The start and end data should be 2019-05-01 to 2020-05-01\n",
    "# Set the parameter tz to \"America/New_York\", \n",
    "# Set this all to the ISO format by calling the isoformat function \n",
    "start_date = pd.Timestamp(\"2019-05-01\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2020-05-01\", tz=\"America/New_York\").isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeframe to one day (1D)\n",
    "timeframe = '1D'\n",
    "\n",
    "# Set number of rows to 1000 to retrieve the maximum amount of rows\n",
    "limit_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_barset() got an unexpected keyword argument 'limit_rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e00c815d88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlimit_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ).df\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_barset() got an unexpected keyword argument 'limit_rows'"
     ]
    }
   ],
   "source": [
    "# Use the Alpaca get_barset function to gather the price information for each ticker\n",
    "# Include the function parameters: tickers, timeframe, start, end, and limit\n",
    "# Be sure to call the df property to ensure that the returned information is set as a DataFrame\n",
    "prices_df = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_date,\n",
    "    end = end_date,\n",
    "    limit_rows = 1000\n",
    ").df\n",
    "\n",
    "# Review the first five rows of the resulting DataFrame \n",
    "prices_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a new DataFrame that holds the closing prices of each stock.\n",
    "\n",
    "1. Create a `closing_prices_df` DataFrame.\n",
    "2. Using a for-loop, for every `ticker` in the `tickers` list, select the `close` price for each ticker in the `prices_df` Dataframe. That expression will be set equal to  the new `closing_prices_df` for the same `ticker`.\n",
    "3. For the new closing_prices_df DataFrame, keep only the date component (drop the time component).\n",
    "4. View the `closing_prices_df` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for holding the closing prices\n",
    "closing_prices_df = pd.DataFrame()\n",
    "\n",
    "# Using a for loop, for every ticker in the tickers list, \n",
    "# Select the close price for each ticker in the prices_df Dataframe\n",
    "# That will be set equal to closing_prices_df for the same ticker value\n",
    "for ticker in tickers:\n",
    "    closing_prices_df[ticker] = prices_df[ticker][\"close\"]\n",
    "\n",
    "# For the new closing_prices_df DataFrame, keep only the date component\n",
    "closing_prices_df.index = closing_prices_df.index.date\n",
    "\n",
    "# View the first and last five rows of the closing_prices_df DataFrame\n",
    "display(closing_prices_df.head())\n",
    "display(closing_prices_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate a daily returns DataFrame that’s based on the closing prices of each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily returns of the closing_prices_df DataFrame using the pct_change function \n",
    "# Be sure to drop the first row of NaN values\n",
    "daily_returns_df = closing_prices_df.pct_change().dropna()\n",
    "\n",
    "# Review the first and last five rows of the daily_returns_df DataFrame\n",
    "display(daily_returns_df.head())\n",
    "display(daily_returns_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate the summary statistics for the daily returns DataFrame. This provides your first review of the distribution information for your stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Pandas describe function, generate summary statistics\n",
    "# for each of the tickers in the daily_returns_df DataFrame\n",
    "daily_returns_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Visualize the distribution of the daily returns DataFrame by creating a histogram plot and a density plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of daily returns across all stocks using a histogram plot\n",
    "# Give the plot a title and adjust the figure size\n",
    "aily_returns_df.plot(\n",
    "    kind=\"hist\",  \n",
    "    figsize=(15,10),\n",
    "    title=\"Daily Returns Histogram\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of daily returns across all stocks using a density plot\n",
    "# Give the plot a title and adjust the figure size\n",
    "daily_returns_df.plot.density(\n",
    "    figsize=(15,10), \n",
    "    title=\"Daily Returns Density Plot\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect on the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** After analyzing the summary statistics, histogram, and density plot for the SPY, LUV, DIS, AAPL, SBUX, and ZM stocks, which do you think is the most volatile stock based on the daily return data? Which is the least volatile?\n",
    "    \n",
    "**Answer:** The most volatile stock is ZM, Zoom Video Communications. The least volatile stock is SPY, SPDR S&P 500 ETF Trust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
